{
  "core.detection.DetectionEngine": {
    "DetectionEngine(...)": "Constructor for the main detection loop coordinator. It takes all its dependencies via injection: `ScreenCapture` for getting images, `TemplateDetector` for finding templates, `SequenceManager` for logic, and `OverlayRenderer` for UI feedback. It also receives the `detectionIntervalMs` configuration, which controls the frequency of the detection loop. It is instantiated by `Main` at startup.",
    "start()": "Starts the main detection loop. It creates a new single-thread `ScheduledExecutorService` and schedules the `processFrame` method to run at a fixed interval defined by `detectionIntervalMs`. This is the primary trigger for all the application's real-time functionality. It is called by `Main` after all other components are initialized. The thread is configured as a daemon to ensure it doesn't prevent the JVM from shutting down.",
    "stop()": "Stops the detection loop. It gracefully shuts down the `ScheduledExecutorService`, clears any active UI overlays, and sets a flag to prevent further processing. This is a critical cleanup step, called by the shutdown hook in `Main` to ensure the application terminates cleanly.",
    "processFrame()": "This is the core method of the application's real-time loop, executed on every scheduled tick. It first checks with the `SequenceManager` if detection is even needed. If so, it captures the screen, gets the current detection requirements (which abilities to look for), and then uses `parallelStream` to have the `TemplateDetector` find each required ability. The results are adapted to screen coordinates and sent to the `SequenceManager` to advance the sequence logic. Finally, it updates the UI overlays. All native `Mat` objects are closed in a `finally` block to prevent memory leaks.",
    "primeActiveSequence()": "An optimization method called once before the detection loop starts. It gets a list of all abilities used in the entire active sequence from the `SequenceManager`. It then performs a single screen capture and uses the `TemplateDetector` to find and cache the locations of all these abilities at once. This 'priming' allows the main detection loop to use more efficient, region-specific searches for subsequent frames, significantly improving performance. It is called by `Main`."
  },
  "core.detection.DetectionResult": {
    "found(String, Point, double, Rectangle, boolean)": "A static factory method for creating a `DetectionResult` that represents a successful template match. It takes the template name, its location, the confidence score, and its bounding box. The `isAlternative` parameter is crucial for the sequence logic, indicating if this result is from an optional part of a sequence step. This method ensures that all successful results are constructed consistently.",
    "notFound(String, boolean)": "A static factory method for creating a `DetectionResult` representing a failed match. It takes the template name and the `isAlternative` flag. It sets default values for location (null) and confidence (0.0). This ensures that the system can still process a list of results even when some templates are not found on the screen, which is a normal part of the application's operation."
  },
  "core.detection.TemplateDetector": {
    "TemplateDetector(TemplateCache, AbilityConfig)": "Constructor for the `TemplateDetector`. It takes the `TemplateCache` as a dependency to get the pre-loaded template images (as OpenCV `Mat` objects) and the `AbilityConfig` to retrieve per-ability settings, such as custom detection thresholds. It also initializes a thread-safe `ConcurrentHashMap` to store the last known locations of templates, which is a key part of its performance optimization strategy. It is instantiated by `Main`.",
    "detectTemplate(Mat, String, boolean)": "The primary public method for finding a template on the screen. It first attempts a highly efficient search in a small region around the template's last known location. If that fails, it performs a full-screen search using `findBestMatch`. If the template is found, its new location is cached for the next frame. This two-tier search strategy (region-first, then full-screen) is a critical performance optimization. This method is called repeatedly by the `DetectionEngine`.",
    "cacheAbilityLocations(Mat, Collection<String>)": "An optimization method used to 'prime' the detector's cache. It takes a screen capture and a collection of ability keys and runs a parallel detection for each one that isn't already in the `lastKnownLocations` cache. This is called once by the `DetectionEngine` at the start of a sequence to find all relevant abilities in a single pass, which makes subsequent frame-by-frame detections much faster by enabling region-specific searches.",
    "findBestMatch(Mat, Mat, String, double, boolean)": "A private, core method that performs the actual template matching using OpenCV's `matchTemplate` function. It handles the complexity of image formats, especially templates with alpha channels which it uses as a mask for more accurate matching. It finds the location with the best match score, converts the score to a confidence value [0-1], and returns a `DetectionResult` if the confidence exceeds the specified threshold. It includes extensive, critical resource management in a `finally` block to prevent native memory leaks from unclosed `Mat` objects."
  }
}